{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import logging \n",
    "import matplotlib.pyplot as plt\n",
    "from utils import send_notice\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 自定义数据集类\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, color_dir, bw_dir, transform=None):\n",
    "        self.color_dir = color_dir\n",
    "        self.bw_dir = bw_dir\n",
    "        self.transform = transform\n",
    "        self.color_images = os.listdir(color_dir)\n",
    "        self.bw_images = os.listdir(bw_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 10000\n",
    "        # return len(self.color_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        color_img_path = os.path.join(self.color_dir, self.color_images[idx])\n",
    "        bw_img_path = os.path.join(self.bw_dir, self.bw_images[idx])\n",
    "        color_img = Image.open(color_img_path).convert('RGB')\n",
    "        bw_img = Image.open(bw_img_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            color_img = self.transform(color_img)\n",
    "            bw_img = self.transform(bw_img)\n",
    "\n",
    "        return bw_img, color_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# U-Net模型\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "        bottom = self.bottleneck(self.pool4(enc4))\n",
    "        \n",
    "        dec4 = self.upconv4(bottom)\n",
    "        dec4 = torch.cat([dec4, enc4], dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        \n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat([dec3, enc3], dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        \n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat([dec2, enc2], dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        \n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat([dec1, enc1], dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        return self.output(dec1)\n",
    "\n",
    "def denormalize(img):\n",
    "    img = img * 0.5 + 0.5\n",
    "    img = img.clamp(0, 1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 13:33:24 INFO: Start loading dataset\n",
      "2024-06-14 13:33:24 INFO: Loading dataset finish\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# todo: train-val split\n",
    "logger.info(\"Start loading dataset\")\n",
    "train_dataset = ColorizationDataset(f'{dir_name}/dataset/images_train', f'{dir_name}/dataset/images_train_black', transform=transform)\n",
    "test_dataset = ColorizationDataset(f'{dir_name}/dataset/images_test', f'{dir_name}/dataset/images_test_black', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "logger.info(\"Loading dataset finish\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 13:33:24 INFO: Start loading model\n",
      "2024-06-14 13:33:30 INFO: Loading model finish\n"
     ]
    }
   ],
   "source": [
    "save_folder = f'{dir_name}/result/run2'\n",
    "logger.info(\"Start loading model\")\n",
    "model = UNet().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "logger.info(\"Loading model finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=50):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    output_result = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for gray_images, color_images in tqdm(train_loader, desc=f\"Train Model, Epoch: {epoch+1}/{epochs}\"):\n",
    "            gray_images = gray_images.cuda()\n",
    "            color_images = color_images.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(gray_images)\n",
    "            loss = criterion(outputs, color_images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * gray_images.size(0)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for gray_images, color_images in tqdm(val_loader, desc=f\"Validate Model, Epoch {epoch+1}/{epochs}\"):\n",
    "                gray_images = gray_images.cuda()\n",
    "                color_images = color_images.cuda()\n",
    "                outputs = model(gray_images)\n",
    "                loss = criterion(outputs, color_images)\n",
    "                val_loss += loss.item() * gray_images.size(0)\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f'Train Loss: {train_loss:.4f}')\n",
    "\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            logger.info(f\"Save Training Result for Epoch {epoch+1}\")\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(train_losses, label='Training Loss')\n",
    "            plt.plot(val_losses, label='Validation Loss')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.title('Training and Validation Loss Over Epochs')\n",
    "            plt.savefig(f'{save_folder}/loss_{epoch+1}.png')\n",
    "            plt.show()\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            gray_image, color_image = next(iter(val_loader))\n",
    "            gray_image = gray_image.cuda()\n",
    "            color_image = color_image.cuda()\n",
    "            with torch.no_grad():\n",
    "                output = model(gray_image)\n",
    "            \n",
    "            gray_image = gray_image.cpu().squeeze(0).squeeze(0)  # 将灰度图像从 (1, 1, H, W) 压缩到 (H, W)\n",
    "            color_image = color_image.cpu().squeeze(0).squeeze(0)\n",
    "            output = denormalize(output.cpu().squeeze(0))\n",
    "            output_result.append(output)\n",
    "            \n",
    "            fig, axes = plt.subplots(10, 2+len(output_result), figsize=(12, 15))\n",
    "\n",
    "            img_num = 10\n",
    "            axes[0, 0].set_title('Origin')\n",
    "            for i in range(len(output_result)):\n",
    "                axes[0, i+1].set_title(f'Epoch_{5*(i+1)}')\n",
    "            axes[0, 1+len(output_result)].set_title('Target')\n",
    "\n",
    "            for i in range(img_num):\n",
    "                axes[i, 0].imshow(gray_image[i][0], cmap='gray')  # 选择第一个灰度图像并显示\n",
    "                axes[i, 0].axis('off')\n",
    "                \n",
    "                for j in range(len(output_result)):\n",
    "                    output = output_result[j]\n",
    "                    axes[i, j+1].imshow(output[i].permute(1, 2, 0).numpy())\n",
    "                    axes[i, j+1].axis('off')\n",
    "\n",
    "                axes[i, 1+len(output_result)].imshow(color_image[i].permute(1, 2, 0).numpy())\n",
    "                axes[i, 1+len(output_result)].axis('off')\n",
    "\n",
    "            plt.savefig(f'{save_folder}/comparison_{epoch+1}.png')\n",
    "            plt.show()\n",
    "            \n",
    "            torch.save(model.state_dict(), f'{save_folder}/colorization_unet_{epoch+1}.pth')\n",
    "            # send_notice(f\"train finish, epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "logger.info(\"Start training model\")\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, epochs=50)\n",
    "logger.info(\"Train model finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "# 加载模型\n",
    "for i in range(10):\n",
    "    epoch = (i+1)*5\n",
    "    model = UNet()\n",
    "    model.load_state_dict(torch.load(f'../result/run1/colorization_unet_{epoch}.pth'))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    gray_image, color_image = next(iter(val_loader))\n",
    "    gray_image = gray_image.cuda()\n",
    "    color_image = color_image.cuda()\n",
    "    with torch.no_grad():\n",
    "        output = model(gray_image)\n",
    "    \n",
    "    gray_image = gray_image.cpu().squeeze(0).squeeze(0)  # 将灰度图像从 (1, 1, H, W) 压缩到 (H, W)\n",
    "    color_image = color_image.cpu().squeeze(0).squeeze(0)\n",
    "    output = denormalize(output.cpu().squeeze(0))\n",
    "    outputs.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 2+len(output_result), figsize=(12, 15))\n",
    "\n",
    "img_num = 10\n",
    "axes[0, 0].set_title('Origin')\n",
    "for i in range(len(outputs)):\n",
    "    axes[0, i+1].set_title(f'Epoch_{5*(i+1)}')\n",
    "axes[0, 1+len(outputs)].set_title('Target')\n",
    "\n",
    "for i in range(img_num):\n",
    "    axes[i, 0].imshow(gray_image[i][0], cmap='gray')  # 选择第一个灰度图像并显示\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    for j in range(len(outputs)):\n",
    "        output = outputs[j]\n",
    "        axes[i, j+1].imshow(output[i].permute(1, 2, 0).numpy())\n",
    "        axes[i, j+1].axis('off')\n",
    "\n",
    "    axes[i, 1+len(outputs)].imshow(color_image[i].permute(1, 2, 0).numpy())\n",
    "    axes[i, 1+len(outputs)].axis('off')\n",
    "\n",
    "plt.savefig(f'{save_folder}/comparison_{epoch+1}.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
